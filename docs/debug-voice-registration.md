# 上司の声登録 - デバッグガイド

## 概要

このドキュメントは、上司の声登録がうまくいかない場合のデバッグ方法を説明します。

## 実装の確認結果

### Azure Speech Service のダイアライゼーション機能の使用状況

✅ **確認結果: 使用している**

上司の声登録機能および1on1測定機能は、Azure Speech Service の以下の機能を使用しています：

1. **ConversationTranscriber**
   - Azure Speech Service のリアルタイム会話文字起こし機能
   - 話者のダイアライゼーション（話者識別）を自動実行
   - 各発話にスピーカーIDを付与

2. **ダイアライゼーション（Speaker Diarization）**
   - 音声から複数の話者を自動的に識別
   - 各発話に対してスピーカーIDを割り当て
   - リアルタイムで動作

## 修正内容

### 以前の実装（問題あり）

```javascript
// シミュレーションのみ - 実際の音声認識なし
async function startVoiceRegistration() {
    // 10秒間カウントダウンするだけ
    // 音声は録音されず、認識も行われていなかった
}
```

### 現在の実装（修正後）

```javascript
// Azure Speech Service を使用した実際の音声認識
async function startVoiceRegistration() {
    // ConversationTranscriber を作成
    const registrationTranscriber = new SpeechSDK.ConversationTranscriber(speechConfig, audioConfig);
    
    // 音声認識を実行
    registrationTranscriber.transcribed = (s, e) => {
        // 認識結果をログ出力
        console.log('スピーカーID:', e.result.speakerId);
        console.log('認識テキスト:', e.result.text);
    };
    
    // 10秒間音声を録音・認識
}
```

## デバッグ方法

### ステップ1: ブラウザのコンソールを開く

1. Google Chrome の場合:
   - F12 キーを押す
   - または 右クリック → 「検証」→ 「Console」タブ

2. Microsoft Edge の場合:
   - F12 キーを押す
   - または 右クリック → 「検証」→ 「コンソール」タブ

### ステップ2: 上司の声を登録

1. 「上司の声登録」タブを開く
2. 「声の登録を開始」ボタンをクリック
3. マイクに向かって自然な声で話す（10秒間）

### ステップ3: コンソールログを確認

登録中、以下のようなログが出力されます：

```
🎙️ 声の登録を開始します...
📌 [デバッグ] Azure Speech Service のダイアライゼーション機能を使用します
🔄 ConversationTranscriber を使用して上司の声を録音します...
📌 [デバッグ] これにより Azure Speech Service のダイアライゼーション機能が使用されます
✅ マイク入力を設定しました
✅ ConversationTranscriber を作成しました（ダイアライゼーション有効）
✅ 上司の声の録音を開始しました
📌 [ダイアライゼーション] Azure Speech Service が話者を自動識別します

🗣️ [音声認識中] { speakerId: "Guest-1", 認識テキスト: "こんにちは", 状態: "認識中" }

✅ ========== 音声認識結果 ==========
📌 [結果 #1] {
    スピーカーID: "Guest-1",
    認識テキスト: "こんにちは、これはテストです。",
    発話時間: "2500ms",
    タイムスタンプ: "14:30:45"
}
📌 [ダイアライゼーション] Azure Speech Service が話者を識別しました
=====================================

👤 [上司の声を登録] スピーカーID: Guest-1

✅ ========== 上司の声の登録完了 ==========
📌 [登録情報] {
    保存されたスピーカーID: "Guest-1",
    登録日時: "2025/10/29 14:30:55",
    Azure_ダイアライゼーション使用: "はい"
}
=========================================
```

## ログの見方

### 正常な場合

✅ **以下のログが表示される:**

1. `✅ ConversationTranscriber を作成しました（ダイアライゼーション有効）`
   - Azure Speech Service の初期化成功

2. `🗣️ [音声認識中]` が複数回表示される
   - 音声が認識されている

3. `✅ ========== 音声認識結果 ==========` が表示される
   - 認識が完了している

4. `スピーカーID: "Guest-1"` などのIDが表示される
   - ダイアライゼーションが動作している

### 問題がある場合

#### パターン1: 音声認識が動作していない

❌ **症状:**
- `🗣️ [音声認識中]` が一度も表示されない
- 認識結果が出力されない

🔍 **原因:**
1. マイクが正しく接続されていない
2. ブラウザのマイク権限が拒否されている
3. Azure Speech Service の設定が間違っている

✅ **解決方法:**
1. マイクの接続を確認
2. ブラウザの設定でマイク権限を許可
3. Azure設定タブでサブスクリプションキーとリージョンを確認

#### パターン2: スピーカーIDが "Unknown"

❌ **症状:**
- `スピーカーID: "Unknown"` と表示される
- ダイアライゼーションが動作していない

🔍 **原因:**
1. Azure Speech Service のダイアライゼーション機能が利用できないリージョン
2. 音声が短すぎて識別できない
3. 環境ノイズが多い

✅ **解決方法:**
1. リージョンを `japaneast` に変更
2. もっと長く話す（3秒以上）
3. 静かな環境で実行

#### パターン3: エラーが表示される

❌ **症状:**
- `❌ 認識開始に失敗しました:` というエラーが表示される

🔍 **原因:**
1. Azure Speech Service のサブスクリプションキーが無効
2. リージョンが間違っている
3. インターネット接続の問題

✅ **解決方法:**
1. Azure ポータルでサブスクリプションキーを再確認
2. リージョン名を確認（例: `japaneast`, `eastus`）
3. インターネット接続を確認

## 1on1測定時のログ

1on1測定を開始すると、以下のようなログが出力されます：

```
🎬 1on1測定を開始します...
📌 ========== Azure Speech Service 設定情報 ==========
📌 [確認] ConversationTranscriber を使用
📌 [確認] ダイアライゼーション機能: 有効
📌 [確認] 話者の自動識別: 有効
📌 [注意] 登録された音声プロファイルとの照合: 未実装
================================================

✅ ConversationTranscriberを作成しました
📌 [ダイアライゼーション] Azure Speech Service が会話中の話者を自動識別します

✅ ========== 1on1測定 - 音声認識結果 ==========
📌 [認識結果] {
    スピーカーID: "Guest-1",
    認識テキスト: "今日の進捗はどうですか？",
    発話時間: "3200ms",
    タイムスタンプ: "14:35:10"
}
📌 [話者識別結果] {
    スピーカーID: "Guest-1",
    識別結果: "上司",
    登録されたプロファイルID: "Guest-1"
}
============================================
```

## 現在の実装の制限事項

### 1. 話者識別の簡易実装

**現在の方式:**
- 最初に話した人を「上司」として識別
- 2番目以降の話者を「部下」として識別
- スピーカーIDの一致で判定

**制限:**
- 登録された音声プロファイルとの照合は行っていない
- 音声の特徴（声質、話し方）での識別は行っていない
- 単純にスピーカーIDの順番で判定

### 2. Azure Speaker Recognition API との統合は未実装

**より高度な話者識別を実現するには:**
- Azure Speaker Recognition API を使用
- 音声プロファイルを作成・登録
- 音声の特徴量で話者を識別
- REST API の呼び出しが必要（ブラウザJavaScript SDKでは未サポート）

### 3. 現在の実装で十分なケース

以下の条件を満たす場合、現在の実装で十分機能します：

✅ **1on1で上司が最初に話す**
- 例: 「今日の調子はどうですか？」と上司から会話を始める

✅ **話者が2人だけ**
- 上司と部下の1対1の会話

✅ **会話中に話者が入れ替わらない**
- 途中で別の人が参加しない

## トラブルシューティング

### Q1: 「音声認識結果」が1つも表示されない

**確認事項:**
1. マイクは正しく接続されていますか？
2. ブラウザでマイクの使用を許可しましたか？
3. 声が小さすぎませんか？（マイクに近づいてください）
4. Azure Speech Service の設定は正しいですか？

### Q2: スピーカーIDが毎回 "Unknown" になる

**確認事項:**
1. Azure Speech Service のリージョンは対応していますか？
   - 推奨: `japaneast`, `eastus`, `westeurope`
2. 発話は3秒以上続けていますか？
3. 環境が静かですか？（ノイズが少ない場所で試してください）

### Q3: 登録したのに1on1測定で話者が識別されない

**確認事項:**
1. 1on1測定で最初に話しているのは上司ですか？
2. 登録時と同じマイクを使用していますか？
3. コンソールログで「最初の話者を上司として登録」が表示されていますか？

## まとめ

### ✅ 実装されている機能

- Azure Speech Service の ConversationTranscriber 使用
- ダイアライゼーション（話者識別）機能の有効化
- リアルタイム音声認識
- スピーカーIDの取得
- 詳細なログ出力

### ⚠️ 制限事項

- 登録された音声プロファイルとの照合は未実装
- 簡易的な話者識別（最初に話した人＝上司）
- Azure Speaker Recognition API は未使用

### 📝 デバッグのポイント

1. ブラウザのコンソールログを必ず確認
2. 音声認識結果とスピーカーIDが表示されるか確認
3. エラーメッセージがあれば詳細を確認
4. 静かな環境で、はっきりと話す

---

**作成日:** 2025年10月29日  
**対象バージョン:** Azure Speech Service版 1.0  
**更新日:** 2025年10月29日
